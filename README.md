
# ğŸ§  Deepfake Video Detection Using ResNeXt + LSTM

This project is a complete pipeline for detecting deepfake videos using deep learning techniques. It includes video preprocessing, a hybrid CNN-LSTM model for spatiotemporal learning, training logic, and prediction with heatmap visualizations.

## ğŸ“‚ Project Structure

```
deepfake-detection/
â”œâ”€â”€ preprocessing_video.py       # Frame extraction and face cropping
â”œâ”€â”€ model_and_train_csv_.py      # Dataset creation, model training & evaluation
â”œâ”€â”€ predict.py                   # Inference with heatmap and confidence
â”œâ”€â”€ Gobal_metadata.csv           # CSV with video labels: REAL or FAKE
â””â”€â”€ checkpoint.pt                # Saved model checkpoint
```

## ğŸš€ Features

- âœ… End-to-end pipeline: From video preprocessing to prediction.
- ğŸ¥ Face-based frame extraction for robust feature learning.
- ğŸ§  Hybrid model: ResNeXt CNN + LSTM for spatial-temporal learning.
- ğŸ“Š Training and validation with performance plots and confusion matrix.
- ğŸ”¥ Heatmap-based interpretability for predictions.

## ğŸ› ï¸ Requirements

Make sure you're using **Google Colab GPU runtime** with the following libraries:

```bash
pip install face_recognition
pip install dlib
```

Also requires: `torch`, `torchvision`, `opencv-python`, `matplotlib`, `numpy`, `seaborn`, `pandas`, `sklearn`

## ğŸ“¦ Dataset

- Videos are expected in `/content/drive/MyDrive/Dataset/`
- Ground truth labels in `Gobal_metadata.csv` with format: `filename,label` where label âˆˆ {REAL, FAKE}

## ğŸ§¼ 1. Preprocessing

Extracts faces from videos and resizes them to `112x112`. Videos with too few frames are ignored.

```bash
python preprocessing_video.py
```

Outputs preprocessed videos to: `/content/drive/MyDrive/New_data/`

## ğŸ‹ï¸â€â™‚ï¸ 2. Model Training

- Uses ResNeXt50 as a feature extractor
- LSTM layers capture temporal features
- Classifies video as REAL or FAKE

```bash
python model_and_train_csv_.py
```

Includes:
- Corrupted video filtering
- Data loader creation
- Model training with accuracy/loss plots
- Confusion matrix visualization

## ğŸ” 3. Inference & Visualization

Run prediction on new videos with confidence score and Class Activation Map (CAM)-based heatmap.

```bash
python predict.py
```

Sample output:
```
/content/drive/MyDrive/Dataset/id0_0003.mp4
Confidence: 97.35%
Prediction: FAKE
```

Also generates a heatmap overlay on the last frame.

## ğŸ§  Model Architecture

```text
Input Video (20 frames) 
     â†“
Face Detection & Resize (112x112)
     â†“
ResNeXt50 (CNN)
     â†“
LSTM (sequence modeling)
     â†“
Fully Connected â†’ Softmax (REAL / FAKE)
```

## ğŸ“Š Results

- âœ… Average Accuracy: ~90% on validation set
- ğŸ“‰ Loss and accuracy plotted per epoch
- ğŸ”¥ Heatmaps show regions influencing prediction

## ğŸ“ Citation & Credits

- FaceForensics++ Dataset: https://github.com/ondyari/FaceForensics
- DFDC: https://www.kaggle.com/c/deepfake-detection-challenge
- Torchvision ResNeXt: https://pytorch.org/vision/stable/models.html

## ğŸ“Œ Notes

- Training assumes your Google Drive is mounted and dataset paths are accessible.
- Works best with a GPU-enabled runtime.
- Code is modular and customizable for other face-based video classification tasks.
